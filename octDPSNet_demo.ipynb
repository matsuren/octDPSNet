{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for octDPSNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show pointclouds\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.octDPSNet import octdpsnet\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from models import octconv\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 0\n",
    "device = torch.device(\"cuda:{}\".format(gpu_id) if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# select data\n",
    "############################\n",
    "# test_folder = './sample_data/sun3d_test_00047/'\n",
    "test_folder = './sample_data/mvs_test_00023/'\n",
    "# test_folder = './sample_data/rgbd_test_00038/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlabel = 64\n",
    "mindepth = 0.5\n",
    "octconv.ALPHA = 0.75\n",
    "# octconv.ALPHA = 0.9375\n",
    "\n",
    "mymodel = octdpsnet(nlabel, mindepth, octconv.ALPHA, True).to(device)\n",
    "mymodel.eval()\n",
    "print('Load:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def ToImg(img):\n",
    "    return img.cpu().numpy().transpose(1,2,0)/2 + 0.5\n",
    "\n",
    "def showImg(img):\n",
    "    ret = ToImg(img)\n",
    "    plt.imshow(ret)\n",
    "    \n",
    "def imread(fname):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "def ToT(img):\n",
    "    img = torch.from_numpy(img.transpose(2, 0, 1)).float()/255\n",
    "    return (img-0.5)*2\n",
    "\n",
    "def preprocess(tgt_img, imgs, ref_poses, intrinsics):\n",
    "    tgt_img = ToT(tgt_img)[np.newaxis]\n",
    "    imgs = [ToT(it)[np.newaxis] for it in imgs]\n",
    "    ref_poses = [torch.from_numpy(it)[np.newaxis].float() for it in ref_poses]\n",
    "    inv_intrinsic = np.linalg.inv(intrinsics)\n",
    "    intrinsics = torch.from_numpy(intrinsics).float()\n",
    "    inv_intrinsic = torch.from_numpy(inv_intrinsic).float()\n",
    "    return tgt_img, imgs, ref_poses, intrinsics, inv_intrinsic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "fname_l = test_folder + '/0000.jpg'\n",
    "fname_r = test_folder + '/0001.jpg'\n",
    "tgt_img = imread(fname_l)\n",
    "img = imread(fname_r)\n",
    "\n",
    "# intrinsics = np.array([[386.8946, 0, 382.7535],\n",
    "#                        [0, 386.8946, 219.6522],\n",
    "#                        [0, 0, 1]])\n",
    "# ref_poses = [np.array([[[0.9360, 0.0590, 0.3470, -566.4332],\n",
    "#                      [-0.0623, 0.9981, -0.0019, 17.1064],\n",
    "#                      [-0.3464, -0.0198, 0.9379,  123.5660]]])]\n",
    "\n",
    "intrinsics = np.loadtxt(test_folder + '/cam.txt')\n",
    "\n",
    "poses = np.loadtxt(test_folder + '/poses.txt')\n",
    "pose_tgt = np.concatenate((poses[0,:].reshape((3,4)), np.array([[0,0,0,1]])), axis=0)\n",
    "for j in [1]:\n",
    "    pose_src = np.concatenate((poses[j,:].reshape((3,4)), np.array([[0,0,0,1]])), axis=0)\n",
    "    pose_rel = pose_src.dot(np.linalg.inv(pose_tgt))\n",
    "    pose = pose_rel[:3,:].reshape((1,3,4)).astype(np.float32)\n",
    "ref_poses = [pose]\n",
    "\n",
    "# visualize\n",
    "fig, ax  = plt.subplots(1, 2, figsize=(12,9))\n",
    "ax = ax.flatten()\n",
    "\n",
    "ax[0].imshow(tgt_img)\n",
    "ax[1].imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess image\n",
    "if device.type == 'cpu':\n",
    "    div_factor = 2\n",
    "    resize_x = 640//div_factor\n",
    "    resize_y = 480//div_factor\n",
    "else:\n",
    "    resize_x = 640\n",
    "    resize_y = 480\n",
    "    \n",
    "print('resize:{}, {}'.format(resize_x,resize_y))\n",
    "\n",
    "h, w, c = tgt_img.shape\n",
    "x_scale = resize_x/w\n",
    "y_scale = resize_y/h\n",
    "intrinsics[0] *= x_scale\n",
    "intrinsics[1] *= y_scale\n",
    "\n",
    "tgt_img = cv2.resize(tgt_img, (resize_x, resize_y))\n",
    "img = cv2.resize(img, (resize_x, resize_y))\n",
    "\n",
    "imgs = [img]  # imgs = [img1, img2]\n",
    "ref_poses = [pose]  # imgs = [pose1, pose2]\n",
    "\n",
    "org_img = np.array(tgt_img, dtype=np.uint8)\n",
    "\n",
    "tgt_img, imgs, ref_poses, intrinsics, inv_intrinsic = preprocess(tgt_img, imgs, ref_poses, intrinsics)\n",
    "\n",
    "showImg(tgt_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    tgt_img = tgt_img.to(device)\n",
    "    imgs = [it.to(device) for it in imgs]\n",
    "    ref_poses = [it.to(device) for it in ref_poses]\n",
    "    intrinsics = intrinsics[np.newaxis].to(device)\n",
    "    inv_intrinsic = inv_intrinsic[np.newaxis].to(device)\n",
    "    ref_poses = torch.cat(ref_poses,1)\n",
    "    output_depth = mymodel(tgt_img, imgs, ref_poses, intrinsics, inv_intrinsic)    \n",
    "    depth = output_depth.squeeze().cpu().numpy()\n",
    "    \n",
    "print('depth max:', depth.max())\n",
    "print('depth min:', depth.min())\n",
    "plt.imshow(depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show PointCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcdCamera(scale=1.0, color=[1, 0, 0]):\n",
    "    points = [[-1, 0.75, 0],[1, 0.75, 0],[1, -0.75, 0],[-1, -0.75, 0],[0,0,0.6]]\n",
    "    lines = [[0,1],[1,2],[2,3],[3,0],\n",
    "             [0,4],[1,4],[2,4],[3,4]]\n",
    "    colors = [color for i in range(len(lines))]\n",
    "    line_set = o3d.geometry.LineSet()\n",
    "\n",
    "    points = np.array(points)*scale\n",
    "    line_set.points = o3d.utility.Vector3dVector(points)\n",
    "    line_set.lines = o3d.utility.Vector2iVector(lines)\n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "    return line_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = org_img\n",
    "img = cv2.resize(img, (resize_x, resize_y))\n",
    "\n",
    "height, width, _ = img.shape\n",
    "cam = intrinsics.cpu().numpy()[0]\n",
    "fx = cam[0,0]\n",
    "fy = cam[1,1]\n",
    "cx = cam[0,2]\n",
    "cy = cam[1,2]\n",
    "cam_o3 = o3d.camera.PinholeCameraIntrinsic(width, height, fx,fy,cx,cy)\n",
    "rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        o3d.geometry.Image(img), o3d.geometry.Image(depth), \n",
    "    depth_scale=1.0, depth_trunc=100, convert_rgb_to_intensity=False)\n",
    "\n",
    "pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, cam_o3)\n",
    "print('save point cloud as results.ply')\n",
    "o3d.io.write_point_cloud('results.ply', pcd)\n",
    "\n",
    "colors = [[i==0, i==1, i==2] for i in range(3)]\n",
    "d = depth\n",
    "camera_scale = d[d>0.01].min()/9\n",
    "cam_ext = ref_poses.cpu().numpy()[0]\n",
    "cam_pcds = []\n",
    "cam_pcd = pcdCamera(-camera_scale, colors[0])\n",
    "cam_pcds.append(cam_pcd)\n",
    "\n",
    "for i, it in enumerate(cam_ext):\n",
    "    cam_pcd = pcdCamera(-camera_scale, colors[i+1])\n",
    "    T = np.concatenate((it, np.array([[0,0,0,1]])), axis=0)\n",
    "    invT = np.linalg.inv(T)\n",
    "    cam_pcd.transform(invT)\n",
    "    cam_pcds.append(cam_pcd)\n",
    "\n",
    "show_pcds = [pcd, *cam_pcds]\n",
    "for it in show_pcds:\n",
    "    it.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "o3d.visualization.draw_geometries(show_pcds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate GIF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T13:34:50.337469Z",
     "start_time": "2019-10-15T13:34:45.894181Z"
    }
   },
   "source": [
    "depth, image, tmp = None, None, None\n",
    "tmp_idx = 0\n",
    "caps = []\n",
    "def rotate_view(vis):\n",
    "    global caps, tmp_idx\n",
    "    \n",
    "    if tmp_idx < 230:\n",
    "        image = vis.capture_screen_float_buffer(False)\n",
    "        caps.append(image)\n",
    "    ctr = vis.get_view_control()\n",
    "    diff = 10#, 14.0\n",
    "    if tmp_idx == 0:\n",
    "        ctr.translate(-30, -50)\n",
    "        ctr.scale(-1.5)\n",
    "        ctr.rotate(0, 100)\n",
    "#         ctr.translate(40, -50)\n",
    "#         ctr.scale(-2)\n",
    "#         ctr.rotate(-80, 30)\n",
    "    if tmp_idx < 25:\n",
    "        ctr.scale(-0.6)\n",
    "    elif tmp_idx < 50:\n",
    "        ctr.rotate(diff,0)\n",
    "    elif tmp_idx < 100:\n",
    "        ctr.rotate(-diff,0)\n",
    "    elif tmp_idx < 125:\n",
    "        ctr.rotate(diff,0)\n",
    "    elif tmp_idx < 150:\n",
    "        ctr.rotate(0, diff*0.8)\n",
    "    elif tmp_idx < 200:\n",
    "        ctr.rotate(0, -diff*0.8)\n",
    "    elif tmp_idx < 225:\n",
    "        ctr.rotate(0, diff*0.8)\n",
    "\n",
    "\n",
    "    tmp_idx += 1\n",
    "    return False\n",
    "\n",
    "o3d.visualization.draw_geometries_with_animation_callback(\n",
    "    [pcd], rotate_view, width=640, height=480)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T13:14:57.114467Z",
     "start_time": "2019-10-15T13:14:56.618325Z"
    }
   },
   "source": [
    "from PIL import Image\n",
    "def fromOpen3DImage(o3d_img):\n",
    "    arr = np.array(np.asarray(o3d_img)*255, dtype=np.uint8)\n",
    "    img = Image.fromarray(arr)\n",
    "    img = img.resize((240, 180))\n",
    "    return img\n",
    "\n",
    "gif_imgs = [fromOpen3DImage(it) for it in caps]\n",
    "gif_imgs[0].save(test_folder + '/out.gif', save_all=True, duration=55, loop=0, append_images=gif_imgs[1::2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
