{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T11:09:35.013049Z",
     "start_time": "2019-07-30T11:09:34.451185Z"
    }
   },
   "outputs": [],
   "source": [
    "from path import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def compute_errors_test(gt, pred):\n",
    "    thresh = np.maximum((gt / pred), (pred / gt))\n",
    "    a1 = (thresh < 1.25   ).mean()\n",
    "    a2 = (thresh < 1.25 ** 2).mean()\n",
    "    a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "    rmse = (gt - pred) ** 2\n",
    "    rmse = np.sqrt(rmse.mean())\n",
    "\n",
    "    rmse_log = (np.log(gt) - np.log(pred)) ** 2\n",
    "    rmse_log = np.sqrt(rmse_log.mean())\n",
    "\n",
    "    abs_diff = np.mean(np.abs(gt - pred))\n",
    "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "\n",
    "    sq_rel = np.mean(((gt - pred)**2) / gt)\n",
    "\n",
    "    return abs_rel, abs_diff, sq_rel, rmse, rmse_log, a1, a2, a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T11:09:35.650274Z",
     "start_time": "2019-07-30T11:09:35.638407Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Test octDPSNet',\n",
    "                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument('data', metavar='DIR',\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('--nlabel', type=int ,default=64, help='number of label')\n",
    "parser.add_argument('--mindepth', type=float ,default=0.5, help='minimum depth')\n",
    "parser.add_argument('--maxdepth', type=float ,default=10, help='maximum depth')\n",
    "args = parser.parse_args('DATASET/demon/test'.split())\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T11:09:35.959636Z",
     "start_time": "2019-07-30T11:09:35.946648Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = args.data\n",
    "ttypes = ['mvs_test.txt', 'sun3d_test.txt', 'rgbd_test.txt', 'scenes11_test.txt']\n",
    "total_num = 0\n",
    "for it in ttypes:\n",
    "    with open(DATA_FOLDER + it + '.json') as f:\n",
    "        total_num += len(json.load(f))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T11:09:57.889983Z",
     "start_time": "2019-07-30T11:09:57.827397Z"
    }
   },
   "outputs": [],
   "source": [
    "basepath = Path('./')\n",
    "gt_depths = sorted((basepath/'gt_depth_results').files('*.npy'))\n",
    "pred_disps = sorted((basepath/'pred_results').files('*.npy'))\n",
    "\n",
    "assert len(gt_depths) == total_num\n",
    "assert len(pred_disps) == total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T11:10:08.723817Z",
     "start_time": "2019-07-30T11:10:01.684449Z"
    }
   },
   "outputs": [],
   "source": [
    "# errors = np.zeros((2, 8, len(gt_depths)+4), np.float32)\n",
    "errors = np.zeros((1, 8, len(gt_depths)), np.float32)\n",
    "for i, (gt_fname, pred_fname) in enumerate(zip(gt_depths, pred_disps)):\n",
    "    tgt_depth = np.load(gt_fname)\n",
    "    output_disp = np.load(pred_fname)\n",
    "    output_depth = args.mindepth * args.nlabel / output_disp\n",
    "    mask = (tgt_depth <= args.maxdepth) & (tgt_depth >= args.mindepth) & (tgt_depth == tgt_depth)\n",
    "    errors[0, :, i] = compute_errors_test(tgt_depth[mask], output_depth[mask])\n",
    "    if i%100 == 0:\n",
    "        print('Processing,,,:',i)\n",
    "\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T11:10:14.228236Z",
     "start_time": "2019-07-30T11:10:14.195939Z"
    }
   },
   "outputs": [],
   "source": [
    "# errors_all[dataset_name] = errors\n",
    "mean_errors = errors.mean(2)\n",
    "\n",
    "error_names = ['abs_rel', 'abs_diff', 'sq_rel', 'rms', 'log_rms', 'a1', 'a2', 'a3']\n",
    "\n",
    "print(str(pred_fname.dirname()))\n",
    "print(\"Depth Results : \")\n",
    "print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format(*error_names))\n",
    "\n",
    "total_num = 0\n",
    "for it in ttypes:\n",
    "    print('dataset:', it.split('_')[0])\n",
    "    with open(DATA_FOLDER + it + '.json') as f:\n",
    "        length = len(json.load(f))\n",
    "        one_errors = errors[:,:,total_num:total_num+length]\n",
    "        total_num += length\n",
    "    print(\"{:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}\".format(*one_errors.mean(2)[0]))\n",
    "print('dataset:', 'ALL')\n",
    "print(\"{:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}\".format(*mean_errors[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T11:34:05.299183Z",
     "start_time": "2019-07-28T11:34:05.294940Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T02:48:52.175538Z",
     "start_time": "2019-07-30T02:48:52.168461Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_fnames = OrderedDict(\n",
    "    {\n",
    "    r'Our ($\\alpha$=0.25)':'metric_csv/a25.csv',\n",
    "    r'Our ($\\alpha$=0.5)':'metric_csv/a50.csv',\n",
    "    r'Our ($\\alpha$=0.75)':'metric_csv/a75.csv',\n",
    "    r'Our ($\\alpha$=0.875)':'metric_csv/a875.csv',\n",
    "    r'Our ($\\alpha$=0.9375)':'metric_csv/a9375.csv',\n",
    "    'DPSNet':'metric_csv/dpsnet.csv',\n",
    "})\n",
    "# csv_fnames = OrderedDict(\n",
    "#     {\n",
    "#     'proposed':'metric_csv/a75.csv',\n",
    "#     'no color':'metric_csv/a75_nocolor.csv',\n",
    "#     'no integration':'metric_csv/a75_justAdd.csv',\n",
    "#     'no alignment':'metric_csv/a75_oldsweeping.csv'\n",
    "# })\n",
    "\n",
    "# csv_fnames = OrderedDict(\n",
    "#     {\n",
    "#     'proposed':'metric_csv/a75.csv',\n",
    "#     'no color':'metric_csv/a75_nocolor.csv',\n",
    "# })\n",
    "# csv_fnames = OrderedDict(\n",
    "#     {\n",
    "#     'a=0.25 (24)':'metric_csv/a25.csv',\n",
    "#     'a=0.9375 (2)':'metric_csv/a9375.csv',\n",
    "#     'dpsnet':'metric_csv/dpsnet.csv',\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T02:48:52.817678Z",
     "start_time": "2019-07-30T02:48:52.810786Z"
    }
   },
   "outputs": [],
   "source": [
    "def loadDFfromCSV(fname):\n",
    "    df = pd.read_csv(fname ,header=2, index_col=0)\n",
    "    df.columns = df.columns.str.replace(' ', '')\n",
    "    if '_' in df.index[0]:\n",
    "        new_index = [it.split('_')[1] for it in df.index]\n",
    "        df.index = new_index\n",
    "        \n",
    "    with open(fname) as f:\n",
    "        header = f.readlines()[:2]\n",
    "        \n",
    "    return header[0].split('_gpu')[0], df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T02:48:53.316111Z",
     "start_time": "2019-07-30T02:48:53.286806Z"
    }
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "key_list = []\n",
    "for key, fname in csv_fnames.items():\n",
    "    h, df = loadDFfromCSV(fname)\n",
    "    print(h)\n",
    "    # add\n",
    "    df_list.append(df)\n",
    "    key_list.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T02:48:53.755155Z",
     "start_time": "2019-07-30T02:48:53.710596Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.precision = 4\n",
    "df = pd.concat(df_list, axis=0, keys=key_list)\n",
    "df = df.swaplevel().sort_index()\n",
    "df = df.reindex(index=df_list[0].index,level=0)\n",
    "df = df.reindex(index=key_list, level=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T02:49:13.658608Z",
     "start_time": "2019-07-30T02:49:13.654929Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T02:59:50.099129Z",
     "start_time": "2019-07-30T02:59:50.081566Z"
    }
   },
   "outputs": [],
   "source": [
    "def highlightDF(df, loc=None):\n",
    "    attr_bold = 'font-weight: {}'.format('bold')\n",
    "    attr_underline = 'text-decoration:underline'\n",
    "    attrs = [attr_bold, attr_underline]\n",
    "    topk = len(attrs)\n",
    "    \n",
    "    min_is_good = ['abs_rel', 'abs_diff', 'sq_rel', 'rms', 'log_rms']\n",
    "    max_is_good = ['a1', 'a2', 'a3']\n",
    "\n",
    "    if loc==None:\n",
    "        add_attr = pd.DataFrame(np.full(df.shape, \"\"), index=df.index, columns=df.columns)\n",
    "\n",
    "        for index in set(df.index.get_level_values(0)):\n",
    "            _decorate(df.loc[index], add_attr.loc[index], min_is_good, topk=topk)\n",
    "            _decorate(df.loc[index], add_attr.loc[index], max_is_good, topk=topk, reverse=True)\n",
    "\n",
    "    else:\n",
    "        # One index\n",
    "        df=df.loc[loc]\n",
    "        add_attr = pd.DataFrame(np.full(df.shape, \"\"), index=df.index, columns=df.columns)\n",
    "\n",
    "        _decorate(df, add_attr, min_is_good, topk=topk)\n",
    "        _decorate(df, add_attr, max_is_good, topk=topk, reverse=True)\n",
    "\n",
    "    add_attr.replace(dict(enumerate(attrs)), inplace=True)\n",
    "    func = lambda x:add_attr\n",
    "    return df.style.apply(func, axis=None)\n",
    "\n",
    "def _decorate(df, add_attr, metrics, topk=1, reverse=False):\n",
    "    for metric in metrics:\n",
    "        roi = df[metric]\n",
    "        for i in range(topk)[::-1]:\n",
    "            sorted_roi = roi.sort_values()\n",
    "            if reverse:\n",
    "                sorted_roi = sorted_roi[::-1]\n",
    "            mask = (roi ==sorted_roi[i])\n",
    "            add_attr[metric][mask]=i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T02:59:50.782606Z",
     "start_time": "2019-07-30T02:59:50.370235Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "highlightDF(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T02:49:02.241293Z",
     "start_time": "2019-07-30T02:49:02.174093Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "highlightDF(df, loc='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T02:49:19.513528Z",
     "start_time": "2019-07-30T02:49:19.509643Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToLatex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T03:02:18.134896Z",
     "start_time": "2019-07-30T03:02:17.965065Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.loc[['mvs', 'sun3d', 'rgbd', 'scenes11']]\n",
    "\n",
    "#### Dataset name #######\n",
    "cvt2multirow = {'mvs':r'{*}{MVS}',\n",
    "               'sun3d':r'{*}{SUN3D}',\n",
    "               'rgbd':r'{30px}{\\centering RGB-D SLAM}',\n",
    "               'scenes11':r'{*}{Scenes11}',\n",
    "               }\n",
    "cvt2multirow\n",
    "multirow_head = r'\\multirow[c]{'+str(len(index_models))+ '}'\n",
    "print(multirow_head + cvt2multirow['mvs'])\n",
    "\n",
    "\n",
    "topk = 2\n",
    "\n",
    "#### Metric name #####\n",
    "colums = ['Abs Rel', 'Abs Diff', 'Sq Rel', 'RMS', 'log RMS',\n",
    "          '$\\delta < 1.25$', '$\\delta < 1.25^2$' '& $\\delta < 1.25^3$']\n",
    "\n",
    "#### Attr #####\n",
    "tex_attr = {'':'', 0:r'\\bfseries', 1:''}\n",
    "tex_attr = {'':'', 0:r'\\bfseries', 1:r'\\underline'}\n",
    "\n",
    "min_is_good = ['abs_rel', 'abs_diff', 'sq_rel', 'rms', 'log_rms']\n",
    "max_is_good = ['a1', 'a2', 'a3']\n",
    "\n",
    "add_attr = pd.DataFrame(np.full(df.shape, \"\"), index=df.index, columns=df.columns)\n",
    "for index in set(df.index.get_level_values(0)):\n",
    "    _decorate(df.loc[index], add_attr.loc[index], min_is_good, topk=topk)\n",
    "    _decorate(df.loc[index], add_attr.loc[index], max_is_good, topk=topk, reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T03:04:51.143493Z",
     "start_time": "2019-07-30T03:04:51.099117Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(r'\\begin{table*}')\n",
    "print(r'\\caption{xxxxxx}')\n",
    "print(r'\\centering')\n",
    "print(r'\\setlength{\\tabcolsep}{3pt}')\n",
    "# print(r'\\begin{tabular}{' + '|l|' + 'r'*5 + '|rrr|' + '}')\n",
    "print(r'\\begin{tabular}{|cc|rrrrr|rrr|}')\n",
    "print(r'\\hline')\n",
    "print(r'\\multicolumn{2}{|c|}{} &  \\multicolumn{5}{c|}{Error (smaller is better)} & \\multicolumn{3}{c|}{Threshold (bigger is better)} \\\\')\n",
    "print('Dataset & Model & ' + ' & '.join(colums) + r' \\\\')\n",
    "print(r'\\hline')\n",
    "#### BODY ####\n",
    "index_datasets = df.index.get_level_values(0).unique()\n",
    "index_models = df.index.get_level_values(1).unique()\n",
    "for idx_data in index_datasets:\n",
    "    for idx_model in index_models:\n",
    "        roi = df.loc[idx_data, idx_model]\n",
    "        roi_attr = add_attr.loc[idx_data, idx_model]\n",
    "\n",
    "        if idx_model == index_models[0]:\n",
    "            series = [multirow_head + cvt2multirow[idx_data]]\n",
    "        else:\n",
    "            series = ['']\n",
    "\n",
    "        series.append(idx_model)\n",
    "        for col in df.columns:\n",
    "            val = roi[col]\n",
    "            attr = roi_attr[col]\n",
    "            series.append('{:.4f}'.format(val))\n",
    "            if tex_attr[attr] != '':\n",
    "                series[-1] = tex_attr[attr] + '{' +series[-1] + '}'\n",
    "        print(' & '.join(series), r'\\\\')\n",
    "    print(r'\\hline')\n",
    "#### BODY END ####\n",
    "print(r'\\end{tabular}')\n",
    "print(r'\\label{tab:xxxx}')\n",
    "print(r'\\end{table*}')\n",
    "\n",
    "\n",
    "# '& xxxxx ' * 8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
